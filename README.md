# ETL--pipeline 

A compact data engineering project executed in **Google Colab** using **Python**, showcasing ETL flow for nested datasets.

##  TechStack
- **Python 3** (Colab)
- **Pandas**, **JSON**, **OpenPyXL**
- **Google Sheets** (final output)
- **GitHub** (version control)
- **APIs** (mocked/dummy for simulation)

##  Functions performed 
- **ETL pipeline**: Extract → Clean → Flatten → Export  
- **Nested data handling**, **data wrangling**
- **Output formatting** for analysis/reporting
- **Automation-ready script** for recurring data jobs

##  Output
Final `.xlsx` output is included in this repo for downloading.

Link to view it in google sheets (https://docs.google.com/spreadsheets/d/1-cBE-msrOB70j3taI5L2IqfuxggX8x1R/edit?usp=drivesdk&ouid=108221278507136154331&rtpof=true&sd=true)


##  How to run
1. Open the Colab notebook.
2. Install required libraries (if not present).
3. Run each cell sequentially.
4. Output gets saved as XLSX file.


## Purpose
 This project automates the end-to-end ETL (Extract, Transform, Load) using Python, public APIs, and Pandas. Raw data is pulled from multiple sources, cleaned, and exported into a clean `.xlsx` file, compatible with Excel and Google Sheets for further analysis or sharing. It demonstrates core data engineering practices like data normalization, transformation, and automated file export using open-source tools.
